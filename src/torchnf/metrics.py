"""
"""
import math
import random
from typing import Optional

import torch
import torchmetrics

import torchnf.utils


class LogStatWeightMetric(torchmetrics.Metric):
    r"""
    Base class for metrics which require log statistical weights.

    'Log-weight' refers to the logarithm of the statistical weight of a
    generated data element, :math:`y` (e.g. the output of a Normalizing
    Flow). The log weight is defined as

    .. math::

        \log w(y) = \log p(y) - \log q(y)

    where :math:`p(y)` and :math:`q(y)` are the target and model
    probability densities, respectively.

    Args:
        reduce: If true, ``compute`` returns a single metric calculated
                using the concatenated log-weights. Otherwise, each
                ``update`` represents its own metric.
    """

    is_differentiable: Optional[bool] = True
    full_state_update: Optional[bool] = False

    def __init__(self) -> None:
        super().__init__()
        self.add_state(
            "log_weights",
            default=list(),
            dist_reduce_fx=None,
        )

    def update(self, log_weights: torch.Tensor) -> None:
        """
        Update the state with log-weights.
        """
        assert (
            log_weights.dim() == 1
        ), "log_weights should be a one-dimensional tensor"
        self.log_weights.append(log_weights)

    def compute(self) -> torch.Tensor:
        raise NotImplementedError


class LogStatWeightMetricMCMC(LogStatWeightMetric):
    """
    Base class for metrics arising from a Metropolis-Hastings simulation.
    """

    is_differentiable: Optional[bool] = False

    def __init__(self) -> None:
        super().__init__()
        self.add_state(
            "history",
            default=list(),
            dist_reduce_fx=None,
        )

    def update(self, log_weights: torch.Tensor) -> None:
        """
        Update the state with log-weights.
        """
        super().update(log_weights)

        indices = torchnf.utils.metropolis_test(log_weights)
        history = [indices[0] == 1] + [
            indices[i + 1] != indices[i] for i in range(len(indices) - 1)
        ]
        history = torch.tensor(history, dtype=torch.int32)

        # Sanity check that num transitions (acceptances) agree
        transitions = set(indices)
        transitions.discard(0)  # there was no transition *to* 0th state
        assert len(transitions) == int(history.sum())

        self.history.append(history)


class ShiftedKLDivergence(LogStatWeightMetric):
    r"""
    Shifted Kullbach-Leibler divergence of the sample.

    .. math::

        \tilde{D}_{KL} = \frac{1}{N} \sum_{\{y\}} - \log w(y)
    """
    higher_is_better: Optional[bool] = False

    def compute(self) -> torch.Tensor:
        """
        Computes the shifted KL.
        """
        log_weights = torch.stack(self.log_weights)
        return log_weights.mean(dim=1).neg()


class EffectiveSampleSize(LogStatWeightMetric):
    r"""
    Effective sample size normalised by the size of the sample.

    The effective sample size is defined by

    .. math::

        N_{eff} = \frac{
            \left[ \frac{1}{N} \sum_{\{y\}} w(y) \right]^2
            }{
            \frac{1}{N} \sum_{\{y\}} w(y)^2
        }

    The quantity returned is actually :math:`N_{eff} / N`.

    References:
        :arxiv:`2101.08176`
    """
    higher_is_better: Optional[bool] = True

    def compute(self) -> torch.Tensor:
        log_weights = torch.stack(self.log_weights)
        ess = torch.exp(
            log_weights.logsumexp(dim=1).mul(2)
            - log_weights.mul(2).logsumexp(dim=1)
        )
        return ess.div(log_weights.shape[1])


class AcceptanceRate(LogStatWeightMetricMCMC):
    r"""
    Fraction of proposals accepted during Metropolis-Hastings.

    Given target probability density :math:`p(y)`, data elements
    generated by the model, :math:`\{ y \sim q(y) \}`, are
    accepted with a probability

    .. math::

        A(y \to y^\prime) = \min \left( 1,
        \frac{q(y)}{p(y)} \frac{p(y^\prime)}{q(y^\prime)} \right) \, .

    Generally speaking, the acceptance rate will be larger if the overlap
    between the model and the target densities is larger.
    """
    higher_is_better: Optional[bool] = True

    def compute(self) -> torch.Tensor:
        history = torch.stack(self.history)
        return history.float().mean(dim=1)


class LongestRejectionRun(LogStatWeightMetricMCMC):
    """
    Largest number of consecutive rejections in the sampling phase.
    """

    higher_is_better: Optional[bool] = False

    def compute(self) -> torch.Tensor:
        history = torch.stack(self.history).bool().transpose(0, 1)
        steps, batches = history.shape

        this = torch.zeros(batches, dtype=torch.int32)
        longest = torch.clone(this)

        for step in history:
            is_rej = step.logical_not().int()  # 1 for rej, 0 for acc
            this.add_(is_rej)  # add 1 for rej
            this.mul_(is_rej)  # mult by 0 for acc
            longest = torch.maximum(longest, this)

        return longest


class IntegratedAutocorrelation(LogStatWeightMetricMCMC):
    r"""
    Integrated autocorrelation derived from the accept/reject history.

    In the limit :math:`t \to \infty` the autocorrelation function can be
    re-interpreted as the probability of failing to transition over a given
    number of Markov chain steps.

    .. math::

        \frac{\Gamma(t)}{\Gamma(0)} =
        \Pr(t \text{ consecutive rejections} )

    An estimate of this probability is obtained by simply summing the
    number of occurrences of a :math:`t` consecutive rejections, and
    normalizing by the largest number of occurrences that are possible;
    that is, by :math:`T - t + 1` where :math:`T` is the total number
    of Markov chain steps.

    References:
        :arxiv:`1904.12072`
    """
    higher_is_better: Optional[bool] = False

    def compute(self) -> torch.Tensor:
        # MCMC history; True = acceptance, False = rejection
        history = torch.stack(self.history).bool().transpose(0, 1)
        steps, batches = history.shape

        # Counter tracks # instances of 't' consec. rej.
        counter = torch.zeros_like(history, dtype=torch.int32)

        # Track no. consec. rej. in current run
        this_rejection_run = torch.zeros(batches, dtype=torch.int32)

        ones = torch.ones_like(history, dtype=torch.int32)
        arange = (
            torch.arange(1, steps + 1).unsqueeze(-1).expand(steps, batches)
        )

        for step in history:
            is_rej = step.logical_not().int()  # 1 for rej, 0 for acc
            this_rejection_run.add_(is_rej)  # add 1 for rej
            this_rejection_run.mul_(is_rej)  # mult by 0 for acc

            # Add one to counter for each i <= t
            counter.add_(ones.mul(arange <= this_rejection_run.unsqueeze(0)))

        # Normalise counter to make it a probability mass function
        # Normalisation = count we would have if all rejected
        autocorrelation = counter.div(arange.flip(dims=(0,)))

        # Return integrated autocorrelation
        return autocorrelation.sum(dim=0).add(0.5)

        """
        tally = [
            0 for _ in range(self.history.numel())
        ]  # first element is t=1
        n_rej = 0

        for step in self.history.tolist():
            if step:  # candidate accepted
                if n_rej > 0:
                    for t in range(n_rej):
                        tally[t] += n_rej - t
                n_rej = 0
            else:  # candidate rejected
                n_rej += 1

        for t in range(n_rej):  # catch last run
            tally[t] += n_rej - t

        # Normalize
        autocorr = [
            a / b for a, b in zip(tally, range(self.history.numel(), 0, -1))
        ]

        integrated_autocorr = 0.5 + sum(autocorr)

        return torch.Tensor([integrated_autocorr])
        """


LogStatWeightMetrics = torchmetrics.MetricCollection(
    metrics=[
        ShiftedKLDivergence(),
        EffectiveSampleSize(),
        AcceptanceRate(),
        LongestRejectionRun(),
        IntegratedAutocorrelation(),
    ],
    compute_groups=[
        ["ShiftedKLDivergence", "EffectiveSampleSize"],
        [
            "AcceptanceRate",
            "LongestRejectionRun",
            "IntegratedAutocorrelation",
        ],
    ],
)
