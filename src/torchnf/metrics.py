"""
"""
import math
import random

import torch

import torchnf.utils

Tensor = torch.Tensor


class LogWeightMetrics:
    r"""
    Lightweight metrics computed using the log-weights of a model output.

    'Log-weight' refers to the logarithm of the statistical weight of a
    generated data element, :math:`y` (e.g. the output of a Normalizing
    Flow). The log weight is defined as

    .. math::

        \log w(y) = \log p(y) - \log q(y)

    where :math:`p(y)` and :math:`q(y)` are the target and model
    probability densities, respectively.

    Args:
        log_weights
            One-dimensional tensor of log-weights, defined above.
    """

    def __init__(self, log_weights: Tensor) -> None:
        assert (
            log_weights.dim() == 1
        ), "log_weights should be a 1-dimensional tensor"
        self._log_weights = log_weights
        self._indices = torchnf.utils.metropolis_test(log_weights)
        self._history = [self._indices[0] == 1] + [
            self._indices[i + 1] != self._indices[i]
            for i in range(len(self._indices) - 1)
        ]

        # Sanity check that num transitions (acceptances) agree
        transitions = set(self._indices)
        transitions.discard(0)  # there was no transition *to* 0th state
        assert len(transitions) == sum(self._history)

    @property
    def kl_divergence(self) -> float:
        r"""
        Kullbach-Leibler divergence of the sample.

        .. math::

            D_{KL} = \frac{1}{N} \sum_{\{y\}} - \log w(y)
        """
        return float(self._log_weights.mean().neg())

    @property
    def acceptance(self) -> float:
        r"""
        Fraction of proposals accepted during Metropolis-Hastings.

        Given target probability density :math:`p(y)`, data elements
        generated by the model, :math:`\{ y \sim q(y) \}`, are
        accepted with a probability

        .. math::

            A(y \to y^\prime) = \min \left( 1,
            \frac{q(y)}{p(y)} \frac{p(y^\prime)}{q(y^\prime)} \right) \, .

        Generally speaking, the acceptance rate will be larger if the overlap
        between the model and the target densities is larger.
        """
        return sum(self._history) / len(self._history)

    @property
    def longest_rejection_run(self) -> int:
        r"""Largest number of consecutive rejections in the sampling phase."""
        n = 0
        n_max = 0
        for step in self._history:
            if not step:
                n += 1
                if n > n_max:
                    n_max = n
            else:
                n = 0
        return n_max

    @property
    def integrated_autocorrelation(self) -> float:
        r"""
        Integrated autocorrelation derived from the accept/reject history.

        In the limit :math:`t \to \infty` the autocorrelation function can be
        re-interpreted as the probability of failing to transition over a given
        number of Markov chain steps.

        .. math::

            \frac{\Gamma(t)}{\Gamma(0)} =
            \Pr(t \text{ consecutive rejections} )

        An estimate of this probability is obtained by simply summing the
        number of occurrences of a :math:`t` consecutive rejections, and
        normalizing by the largest number of occurrences that are possible;
        that is, by :math:`T - t + 1` where :math:`T` is the total number
        of Markov chain steps.

        References:
            :arxiv:`1904.12072`
        """
        tally = [0 for _ in range(len(self._history))]  # first element is t=1
        n_rej = 0

        for step in self._history:
            if step:  # candidate accepted
                if n_rej > 0:
                    for t in range(n_rej):
                        tally[t] += n_rej - t
                n_rej = 0
            else:  # candidate rejected
                n_rej += 1

        for t in range(n_rej):  # catch last run
            tally[t] += n_rej - t

        # Normalize
        autocorr = [
            a / b for a, b in zip(tally, range(len(self._history), 0, -1))
        ]

        return 0.5 + sum(autocorr)

    @property
    def effective_sample_size(self) -> float:
        r"""
        Effective sample size normalised by the size of the sample.

        .. math::

            N_{eff} = \frac{
                \left[ \frac{1}{N} \sum_{\{y\}} w(y) \right]^2
                }{
                \frac{1}{N} \sum_{\{y\}} w(y)^2
            }

        References:
            :arxiv:`2101.08176`
        """
        ess = torch.exp(
            self._log_weights.logsumexp(dim=0).mul(2)
            - self._log_weights.mul(2).logsumexp(dim=0)
        )
        return float(ess.div(len(self._log_weights)))

    def asdict(self) -> dict[str, float]:
        """
        Returns the computed metrics as a dictionary."""
        attrs = [
            "acceptance",
            "kl_divergence",
            "longest_rejection_run",
            "integrated_autocorrelation",
            "effective_sample_size",
        ]
        return {attr: getattr(self, attr) for attr in attrs}
